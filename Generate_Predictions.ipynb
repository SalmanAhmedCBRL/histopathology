{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data_Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('../../Further_Patches/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.DataFrame(data=files, columns=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TEST TCGA\n",
    "x = files[\"filename\"].str.split(\"_\", n = 4, expand = True)\n",
    "files[\"SVS_NO\"] = x[x.columns[-4]]\n",
    "files[\"ROW\"] = x[x.columns[-3]]\n",
    "files[\"COL\"] = x[x.columns[-2]]\n",
    "files[\"ROW\"] = files[\"ROW\"].astype('int')\n",
    "files[\"COL\"] = files[\"COL\"].astype('int')\n",
    "y = x[x.columns[-1]].str.split(\".\", n = 1, expand = True)\n",
    "files[\"Class_Name\"] = y[y.columns[0]]\n",
    "files[\"Class_Name\"] = files[\"Class_Name\"].astype('int')\n",
    "x = files[\"SVS_NO\"].str.split(\"-\", n = 5, expand = True)\n",
    "files[\"SVS_NO\"] = x[x.columns[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR Train bach\n",
    "x = files[\"filename\"].str.split(\"_\", n = 3, expand = True)\n",
    "y = x[x.columns[3]].str.split(\".\", n = 1, expand = True)\n",
    "files[\"SVS_NO\"] = x[x.columns[0]]\n",
    "files[\"Class_Name\"] = y[y.columns[0]]\n",
    "files[\"Class_Name\"] = files[\"Class_Name\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files['filename'] = '../../Further_Patches/' + files['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>SVS_NO</th>\n",
       "      <th>ROW</th>\n",
       "      <th>COL</th>\n",
       "      <th>Class_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1....</td>\n",
       "      <td>A0BD</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1....</td>\n",
       "      <td>A0BD</td>\n",
       "      <td>146</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1....</td>\n",
       "      <td>A0BD</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../Further_Patches/TCGA-BH-A0BO-01Z-00-DX1....</td>\n",
       "      <td>A0BO</td>\n",
       "      <td>65</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../Further_Patches/TCGA-BH-A0BO-01Z-00-DX1....</td>\n",
       "      <td>A0BO</td>\n",
       "      <td>63</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename SVS_NO  ROW  COL  \\\n",
       "0  ../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1....   A0BD    3   92   \n",
       "1  ../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1....   A0BD  146   42   \n",
       "2  ../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1....   A0BD  148   72   \n",
       "3  ../../Further_Patches/TCGA-BH-A0BO-01Z-00-DX1....   A0BO   65  124   \n",
       "4  ../../Further_Patches/TCGA-BH-A0BO-01Z-00-DX1....   A0BO   63   95   \n",
       "\n",
       "   Class_Name  \n",
       "0           0  \n",
       "1           0  \n",
       "2          -1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_Patches :  73815\n"
     ]
    }
   ],
   "source": [
    "print (\"Total_Patches : \", files.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avalable_svs = np.unique(files.SVS_NO.astype('str'), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A0BD', 'A0BO', 'A0CQ'], dtype=object), array([38247, 30033,  5535]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_avalable_svs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Dryad Label for Invasive and Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#files['Class_Name'][files['Class_Name'] > 0] = 1 #FOR TRAIN BACH\n",
    "files['Class_Name'][files['Class_Name'] < 0] = 1 #FOR TEST TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A0BD', 'A0BO', 'A0CQ'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(files.SVS_NO.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A0BD', 'A0BO', 'A0CQ'], dtype=object), array([38247, 30033,  5535]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_all_avalable_svs = np.unique(files.SVS_NO.astype('str'), return_counts=True)\n",
    "training_all_avalable_svs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Total_Patches :  73815\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Total_Patches : \", files.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S-Score Calculation (Metric used in ICIAR 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_s_score(x, y):\n",
    "    a = 0.0000000001\n",
    "    nom = np.sum(np.abs(x-y))\n",
    "    xbin = x.copy()\n",
    "    ybin = y.copy()\n",
    "    xbin[xbin!=0] = 1.0\n",
    "    ybin[ybin!=0] = 1.0\n",
    "    temp = 1.0 - ((1.0 - xbin) * (1.0 - ybin))\n",
    "    v = np.abs(y - 3)\n",
    "    max_term = np.max(np.column_stack([y, v]), axis=1)\n",
    "    temp1 = max_term * temp\n",
    "    denom = np.sum(temp1)\n",
    "    final = nom / (denom + a)\n",
    "    return (1 - final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import itertools\n",
    "import fnmatch\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "from scipy.misc import imresize, imread\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import keras\n",
    "from keras import layers\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json,load_model,Model\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
    "from keras.utils import layer_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, UpSampling2D , Conv2D, MaxPool2D, MaxPooling2D,Input,Concatenate,GlobalAveragePooling2D,GlobalMaxPooling2D,ZeroPadding2D,AveragePooling2D,Reshape,merge,Convolution2D\n",
    "%matplotlib inline\n",
    "from keras import layers\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import efficientnet.keras as efn \n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras_radam import RAdam\n",
    "from keras import backend as K\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To set class_mode of generator we need to change label from dtype integer to dtype string\n",
    "files['Class_Name'] = files['Class_Name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b0 (Model)      (None, 1280)              4049564   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,221,853\n",
      "Trainable params: 4,179,837\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Complete_model_effnet_b0_5.h5', compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "def create_test_gen(Xfiles):\n",
    "    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n",
    "        Xfiles,\n",
    "        directory='.',\n",
    "        x_col='filename',\n",
    "        class_mode=None,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38247 validated image filenames.\n",
      "38247/38247 [==============================] - 335s 9ms/step\n",
      "0.9176928909456951\n",
      "0.9176928909456951\n",
      "0.7107440995537905\n",
      "0.9020330769885566\n",
      "[[33725   350]\n",
      " [ 2798  1374]]\n",
      "Found 30033 validated image filenames.\n",
      "30033/30033 [==============================] - 258s 9ms/step\n",
      "0.9850497785768988\n",
      "0.9850497785768988\n",
      "0.8832636528646592\n",
      "0.9853800644647827\n",
      "[[28814   270]\n",
      " [  179   770]]\n",
      "Found 5535 validated image filenames.\n",
      "5535/5535 [==============================] - 48s 9ms/step\n",
      "0.9192411924119241\n",
      "0.9192411924119241\n",
      "0.714265041868574\n",
      "0.9212962007471496\n",
      "[[4888  247]\n",
      " [ 200  200]]\n"
     ]
    }
   ],
   "source": [
    "for each in training_all_avalable_svs[0]:\n",
    "    Xfiles = files[files.SVS_NO == each].copy()\n",
    "    test_gen = create_test_gen(Xfiles)\n",
    "    predictions = model.predict_generator(test_gen, steps=len(test_gen), verbose=1)\n",
    "    #pred = np.argmax(predictions, axis=1)\n",
    "    pred = predictions.copy()\n",
    "    pred[pred > 0.5] = 1\n",
    "    pred[pred <= 0.5] = 0\n",
    "    print (accuracy_score(Xfiles.Class_Name.astype('int'), pred))\n",
    "    print (f1_score(Xfiles.Class_Name.astype('int'), pred.astype('int'), average='micro'))\n",
    "    print (f1_score(Xfiles.Class_Name.astype('int'), pred.astype('int'), average='macro'))\n",
    "    print (f1_score(Xfiles.Class_Name.astype('int'), pred.astype('int'), average='weighted'))\n",
    "    print (confusion_matrix(Xfiles.Class_Name.astype('int'), pred.astype('int')))\n",
    "    Xfiles['predictions_epochs_3'] = predictions.copy()\n",
    "    Xfiles.to_csv(each + '_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

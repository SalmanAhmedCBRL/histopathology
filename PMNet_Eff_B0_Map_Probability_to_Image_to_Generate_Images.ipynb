{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"},"colab":{"name":"TCGA_Images_Generation.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Kegmbnl0GZzK","colab_type":"code","colab":{},"outputId":"d9f5357e-f014-4f84-e756-012a4f358bcb"},"source":["import os\n","import json\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import keras\n","import pandas as pd\n","import numpy as np\n","import os\n","from glob import glob\n","import itertools\n","import fnmatch\n","import random\n","import matplotlib.pylab as plt\n","import cv2\n","from scipy.misc import imresize, imread\n","import sklearn\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n","from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","import keras\n","from keras import layers\n","from tqdm import tqdm\n","from keras import backend as K\n","from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential, model_from_json,load_model,Model\n","from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n","from keras.utils import layer_utils\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, UpSampling2D , Conv2D, MaxPool2D, MaxPooling2D,Input,Concatenate,GlobalAveragePooling2D,GlobalMaxPooling2D,ZeroPadding2D,AveragePooling2D,Reshape,merge,Convolution2D\n","%matplotlib inline\n","from keras import layers\n","from keras.applications import MobileNetV2\n","from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.optimizers import Adam\n","import tensorflow as tf\n","from tqdm import tqdm\n","import efficientnet.keras as efn \n","from keras.layers import Dense\n","from keras.optimizers import Adam, Nadam\n","from keras_radam import RAdam\n","from keras import backend as K\n","from sklearn.utils import class_weight"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/home/qali/anaconda3/envs/py37_gpu_env/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n","  from numpy.core.umath_tests import inner1d\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6yRx3XkLGZzg","colab_type":"code","colab":{}},"source":["grounds = 'Ground_Truths/'\n","originals = 'Originals/'\n","tcga_prediction_file = 'A0CP_Predictions.csv'\n","tcga_patches_direction = '../../Dataset/X1_P/TCGA-A2-A0CP-01Z-00-DX1.ECFD263C-BB17-4ADA-8F2C-654C2AA4C45F'\n","prediction_directory = 'Predictions/'\n","probability_dir = 'Probability_Map/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"azQFZGQWGZzs","colab_type":"code","colab":{}},"source":["def generate_results(grounds = 'Ground_Truths/', originals = 'Originals/', tcga_prediction_file = 'A0CP_Predictions.csv',\n","tcga_patches_direction = '../../Dataset/X1_P/TCGA-A2-A0CP-01Z-00-DX1.ECFD263C-BB17-4ADA-8F2C-654C2AA4C45F', \n","    prediction_directory = 'Predictions/', probability_dir = 'Probability_Map/', no_org = True, map_on_whole=True):\n","  \n","\n","  \n","    svs_current = pd.read_csv(tcga_prediction_file)\n","    x = svs_current[\"filename\"].str.split(\"_\", n = 4, expand = True)\n","    svs_current[\"SVS_NO\"] = x[x.columns[-4]]\n","    svs_current[\"ROW\"] = x[x.columns[-3]]\n","    svs_current[\"COL\"] = x[x.columns[-2]]\n","    svs_current[\"ROW\"] = svs_current[\"ROW\"].astype('int')\n","    svs_current[\"COL\"] = svs_current[\"COL\"].astype('int')\n","    x = svs_current[\"SVS_NO\"].str.split(\"-\", n = 5, expand = True)\n","    svs_current[\"SVS_NO\"] = x[x.columns[2]]\n","    svs_current = svs_current.sort_values(['SVS_NO','ROW', 'COL'])\n","    total_rows = svs_current.ROW.max() #ROWS\n","    total_cols = svs_current.COL.max() #COLS\n","    classes = svs_current.Class_Name.values\n","    preds = svs_current.predictions_epochs_3.values\n","    SVS_NAME = svs_current.SVS_NO.unique()[0]\n","    \n","    #PREDICTIONS\n","    i = 0\n","    r = 0\n","    while r <= total_rows:\n","        c = 0\n","        while c <= total_cols:\n","            temp = np.zeros(shape=(5,5))\n","            temp = temp + preds[i]\n","            if c == 0:\n","                each_complete_row = temp.copy()\n","            else:\n","                each_complete_row = np.column_stack([each_complete_row, temp])\n","            c += 1\n","            i += 1\n","        if r == 0:\n","            cummulative_rows = each_complete_row.copy()\n","        else:\n","            cummulative_rows = np.row_stack([cummulative_rows, each_complete_row])\n","        r += 1\n","    w = min(cummulative_rows.shape[0], cummulative_rows.shape[1])\n","    cummulative_rows[cummulative_rows>=0.5] = 1\n","    cummulative_rows[cummulative_rows<0.5] = 0\n","    cummulative_rows = cv2.resize(cummulative_rows, (w, w), interpolation=cv2.INTER_AREA)\n","    blank_img = np.zeros(shape=(cummulative_rows.shape[0], cummulative_rows.shape[1], 3))\n","    blank_img[:, :, 0][cummulative_rows==0] = 255.0\n","    blank_img[:, :, 1][cummulative_rows==0] = 255.0\n","    blank_img[:, :, 2][cummulative_rows==0] = 255.0\n","    prediction_sample = cummulative_rows.copy()\n","    save_name = prediction_directory + '/' + SVS_NAME +'.png'\n","    cv2.imwrite(save_name, blank_img)\n","    \n","    #GROUND_TRUTH\n","    i = 0\n","    r = 0\n","    while r <= total_rows:\n","        c = 0\n","        while c <= total_cols:\n","            temp = np.zeros(shape=(5,5))\n","            if classes[i] != 0:\n","                temp = temp + 1.0\n","            if c == 0:\n","                each_complete_row = temp.copy()\n","            else:\n","                each_complete_row = np.column_stack([each_complete_row, temp])\n","            c += 1\n","            i += 1\n","        if r == 0:\n","            cummulative_rows = each_complete_row.copy()\n","        else:\n","            cummulative_rows = np.row_stack([cummulative_rows, each_complete_row])\n","        r += 1\n","    w = min(cummulative_rows.shape[0], cummulative_rows.shape[1])\n","    cummulative_rows = cv2.resize(cummulative_rows, (w, w), interpolation=cv2.INTER_AREA)\n","    blank_img = np.zeros(shape=(cummulative_rows.shape[0], cummulative_rows.shape[1], 3))\n","    blank_img[:, :, 0][cummulative_rows==0] = 255.0\n","    blank_img[:, :, 1][cummulative_rows==0] = 255.0\n","    blank_img[:, :, 2][cummulative_rows==0] = 255.0\n","    save_name = grounds + '/' + SVS_NAME +'.png'\n","    cv2.imwrite(save_name, blank_img)\n","    \n","    if no_org:\n","        #ORIGINAL\n","        class_mod = classes.copy()\n","        class_mod[class_mod == 1] = -1\n","        i = 0\n","        r = 0\n","        while r <= total_rows:\n","            c = 0\n","            while c <= total_cols:\n","                patch_name = tcga_patches_direction + '_' + str(r) + '_' + str(c) + '_' + str(class_mod[i]) + '.png'\n","                temp = cv2.imread(patch_name)\n","#                print (patch_name)\n","                temp = cv2.resize(temp, (5,5), interpolation=cv2.INTER_AREA)\n","                if c == 0:\n","                    each_complete_row = temp.copy()\n","                else:\n","                    each_complete_row = np.column_stack([each_complete_row, temp])\n","                c += 1\n","                i += 1\n","            if r == 0:\n","                cummulative_rows = each_complete_row.copy()\n","            else:\n","                cummulative_rows = np.row_stack([cummulative_rows, each_complete_row])\n","            r += 1\n","        w = min(cummulative_rows.shape[0], cummulative_rows.shape[1])\n","        cummulative_rows = cv2.resize(cummulative_rows, (w, w), interpolation=cv2.INTER_AREA)\n","        save_name = originals + '/' + SVS_NAME +'.png'\n","        cv2.imwrite(save_name, cummulative_rows)\n","    \n","    #PROBABILITY_MAP\n","    i = 0\n","    r = 0\n","    while r <= total_rows:\n","        c = 0\n","        while c <= total_cols:\n","            temp = np.zeros(shape=(5,5,3))\n","            if preds[i] < 0.5:\n","                temp[:, :, 0] = (1-preds[i]) * 255.0\n","                temp[:, :, 1] = preds[i] * 255.0\n","                temp[:, :, 2] = preds[i] * 255.0\n","            else:\n","                temp[:, :, 0] = preds[i] * 255.0\n","                temp[:, :, 1] = preds[i] * 255.0\n","                temp[:, :, 2] = (1-preds[i]) * 255.0\n","            if c == 0:\n","                each_complete_row = temp.copy()\n","            else:\n","                each_complete_row = np.column_stack([each_complete_row, temp])\n","            c += 1\n","            i += 1\n","        if r == 0:\n","            cummulative_rows = each_complete_row.copy()\n","        else:\n","            cummulative_rows = np.row_stack([cummulative_rows, each_complete_row])\n","        r += 1\n","    w = min(cummulative_rows.shape[0], cummulative_rows.shape[1])\n","    cummulative_rows = cv2.resize(cummulative_rows, (w, w), interpolation=cv2.INTER_AREA)\n","    if map_on_whole:\n","        cummulative_rows[:, :, 0][prediction_sample == 0] = 255.0\n","        cummulative_rows[:, :, 1][prediction_sample == 0] = 255.0\n","        cummulative_rows[:, :, 2][prediction_sample == 0] = 255.0\n","    save_name = probability_dir + '/' + SVS_NAME +'.png'\n","    cv2.imwrite(save_name, cummulative_rows)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"seSN7z7XGZz2","colab_type":"code","colab":{}},"source":["generate_results(no_org=True, map_on_whole=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmfLkH9GGZz9","colab_type":"code","colab":{}},"source":["generate_results(tcga_prediction_file='A0BD_predictions.csv', tcga_patches_direction='../../Further_Patches/TCGA-BH-A0BD-01Z-00-DX1.CD4A6FC2-BA8C-4E30-972A-E6CD1BEAD8AD')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qeX5Q7EGZ0F","colab_type":"code","colab":{}},"source":["generate_results(tcga_prediction_file='A0CQ_predictions.csv', tcga_patches_direction='../../Further_Patches/TCGA-A2-A0CQ-01Z-00-DX1.4E5FB4E5-A08C-4C87-A3BE-0640A95AE649')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9dXAOKNGZ0M","colab_type":"code","colab":{}},"source":["generate_results(tcga_prediction_file='A0BO_predictions.csv', tcga_patches_direction='../../Further_Patches/TCGA-BH-A0BO-01Z-00-DX1.1A704471-FEB3-40F9-9838-3E347A18285F')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkFxbQHGGZ0S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}